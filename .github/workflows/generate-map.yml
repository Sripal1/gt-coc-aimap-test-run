name: Generate Research Map

on:
  workflow_dispatch:

# Only allow one run at a time per repo
concurrency:
  group: generate-map
  cancel-in-progress: false

permissions:
  contents: write
  pages: write
  id-token: write

jobs:
  prepare:
    name: Prepare scrape chunks
    runs-on: ubuntu-latest
    timeout-minutes: 5
    outputs:
      matrix: ${{ steps.split.outputs.matrix }}
      chunk_count: ${{ steps.split.outputs.chunk_count }}
      provider: ${{ steps.config.outputs.provider }}
      api_key_env: ${{ steps.config.outputs.api_key_env }}
      researchers_file: ${{ steps.config.outputs.researchers_file }}
      max_threads: ${{ steps.config.outputs.max_threads }}
      max_requests_per_ip: ${{ steps.config.outputs.max_requests_per_ip }}
      max_retries: ${{ steps.config.outputs.max_retries }}
      profiles_dir: ${{ steps.config.outputs.profiles_dir }}
      output_dir: ${{ steps.config.outputs.output_dir }}
      chunk_size: ${{ steps.config.outputs.chunk_size }}
    steps:
      - uses: actions/checkout@v4
        with:
          ref: main
          fetch-depth: 0

      - name: Wait for config file
        run: |
          echo "=== Debug: initial state ==="
          echo "Files in repo root:"
          ls -la
          echo "Git log:"
          git log --oneline -5
          echo "==========================="
          for i in $(seq 1 20); do
            if [ -f researchmap.config.yaml ]; then
              echo "Config file found on attempt $i"
              exit 0
            fi
            echo "Config not found (attempt $i/20), fetching latest..."
            git fetch origin main
            git reset --hard origin/main
            sleep 5
          done
          echo "ERROR: researchmap.config.yaml not found after 20 attempts"
          echo "Final files:"
          ls -la
          exit 1

      - name: Parse config
        id: config
        run: |
          python3 -c "
          import re, os
          config = {}
          with open('researchmap.config.yaml') as f:
              for line in f:
                  line = line.strip()
                  if not line or line.startswith('#'):
                      continue
                  m = re.match(r'(\w+):\s*\"?([^\"]*)\"?', line)
                  if m:
                      config[m.group(1)] = m.group(2).strip()
          # Map config keys to output names
          mapping = {
              'llm_provider': 'provider',
              'llm_api_key_env': 'api_key_env',
              'researchers_file': 'researchers_file',
              'scraper_max_threads': 'max_threads',
              'scraper_max_requests_per_ip': 'max_requests_per_ip',
              'scraper_max_retries': 'max_retries',
              'profiles_dir': 'profiles_dir',
              'output_dir': 'output_dir',
              'chunk_size': 'chunk_size',
          }
          with open(os.environ['GITHUB_OUTPUT'], 'a') as out:
              for yaml_key, output_key in mapping.items():
                  value = config.get(yaml_key, '')
                  if output_key == 'chunk_size' and not value:
                      value = '50'
                  out.write(f'{output_key}={value}\n')
                  print(f'  {output_key}={value}')
          "

      - name: Compute chunk matrix
        id: split
        run: |
          RESEARCHERS_FILE="${{ steps.config.outputs.researchers_file }}"
          CHUNK_SIZE="${{ steps.config.outputs.chunk_size }}"
          # Count data rows (exclude header)
          TOTAL=$(tail -n +2 "$RESEARCHERS_FILE" | wc -l | xargs)
          # Compute number of chunks (ceiling division)
          CHUNKS=$(( (TOTAL + CHUNK_SIZE - 1) / CHUNK_SIZE ))
          if [ "$CHUNKS" -lt 1 ]; then CHUNKS=1; fi
          # Build JSON array [0, 1, 2, ...]
          MATRIX=$(python3 -c "import json; print(json.dumps(list(range($CHUNKS))))")
          echo "matrix=$MATRIX" >> "$GITHUB_OUTPUT"
          echo "chunk_count=$CHUNKS" >> "$GITHUB_OUTPUT"
          echo "Splitting $TOTAL researchers into $CHUNKS chunks of $CHUNK_SIZE"

  scrape:
    name: Scrape chunk ${{ matrix.chunk }}
    needs: prepare
    runs-on: ubuntu-latest
    timeout-minutes: 360
    strategy:
      matrix:
        chunk: ${{ fromJson(needs.prepare.outputs.matrix) }}
      fail-fast: false
    steps:
      - uses: actions/checkout@v4

      - name: Install Tor
        run: |
          sudo apt-get update -qq
          sudo apt-get install -y -qq tor

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install ScholarMine
        run: pip install git+https://github.com/Sripal1/scholarmine.git

      - name: Extract chunk from researchers CSV
        run: |
          python3 pipeline/split_csv.py \
            "${{ needs.prepare.outputs.researchers_file }}" \
            ${{ matrix.chunk }} \
            ${{ needs.prepare.outputs.chunk_size }} \
            chunk_researchers.csv

      - name: Run ScholarMine scraper
        run: |
          scholarmine chunk_researchers.csv \
            --max-threads "${{ needs.prepare.outputs.max_threads }}" \
            --max-requests-per-ip "${{ needs.prepare.outputs.max_requests_per_ip }}" \
            --max-retries "${{ needs.prepare.outputs.max_retries }}" \
            --output-dir "${{ needs.prepare.outputs.profiles_dir }}"

      - name: Upload profiles artifact
        uses: actions/upload-artifact@v4
        with:
          name: researcher-profiles-${{ matrix.chunk }}
          path: ${{ needs.prepare.outputs.profiles_dir }}/
          retention-days: 1

  process:
    name: Run data pipeline
    needs: [prepare, scrape]
    runs-on: ubuntu-latest
    timeout-minutes: 120
    steps:
      - uses: actions/checkout@v4
        with:
          ref: main
          fetch-depth: 0

      - name: Pull latest changes
        run: git pull origin main

      - name: Download all chunk artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: researcher-profiles-*
          path: ${{ needs.prepare.outputs.profiles_dir }}/
          merge-multiple: true

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install pipeline dependencies
        run: pip install -r pipeline/requirements.txt

      - name: Run pipeline
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: |
          python pipeline/run_pipeline.py \
            --profiles-dir "${{ needs.prepare.outputs.profiles_dir }}" \
            --output-dir "${{ needs.prepare.outputs.output_dir }}" \
            --provider "${{ needs.prepare.outputs.provider }}"

      - name: Commit pipeline output
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add "${{ needs.prepare.outputs.profiles_dir }}/" "${{ needs.prepare.outputs.output_dir }}/"
          git commit -m "Add scraped profiles and pipeline output" || echo "No changes to commit"
          git push

      - name: Upload pipeline output
        uses: actions/upload-artifact@v4
        with:
          name: pipeline-output
          path: ${{ needs.prepare.outputs.output_dir }}/
          retention-days: 1

  deploy:
    name: Build & deploy to GitHub Pages
    needs: [prepare, process]
    runs-on: ubuntu-latest
    timeout-minutes: 15
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    steps:
      - uses: actions/checkout@v4
        with:
          ref: main
          fetch-depth: 0

      - name: Pull latest changes
        run: git pull origin main

      - name: Parse config
        id: config
        run: |
          python3 -c "
          import re, os
          config = {}
          with open('researchmap.config.yaml') as f:
              for line in f:
                  line = line.strip()
                  if not line or line.startswith('#'):
                      continue
                  m = re.match(r'(\w+):\s*\"?([^\"]*)\"?', line)
                  if m:
                      config[m.group(1)] = m.group(2).strip()
          repo = os.environ['GITHUB_REPOSITORY'].split('/')[-1]
          with open(os.environ['GITHUB_OUTPUT'], 'a') as out:
              out.write(f'output_dir={config.get(\"output_dir\", \"pipeline-output\")}\n')
              out.write(f'university_name={config.get(\"university_name\", \"\")}\n')
              out.write(f'department_name={config.get(\"department_name\", \"\")}\n')
              out.write(f'color_theme={config.get(\"color_theme\", \"\")}\n')
              out.write(f'base_path=/{repo}/\n')
          "

      - name: Download pipeline output
        uses: actions/download-artifact@v4
        with:
          name: pipeline-output
          path: ${{ steps.config.outputs.output_dir }}/

      - name: Copy data to frontend public directory
        run: |
          OUTPUT="${{ steps.config.outputs.output_dir }}"
          # data.ndjson and grid.json → public/data/
          mkdir -p public/data
          cp "${OUTPUT}/data.ndjson" public/data/data.ndjson
          cp "${OUTPUT}/grid.json" public/data/grid.json
          # Researcher images → public/images/researchers/
          if [ -d "${OUTPUT}/public/images/researchers" ]; then
            mkdir -p public/images/researchers
            cp -r "${OUTPUT}/public/images/researchers/"* public/images/researchers/
          fi

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Install pnpm
        run: npm install -g pnpm

      - name: Install frontend dependencies
        run: pnpm install --frozen-lockfile

      - name: Build frontend
        env:
          VITE_BASE_PATH: ${{ steps.config.outputs.base_path }}
          VITE_UNIVERSITY_NAME: ${{ steps.config.outputs.university_name }}
          VITE_DEPARTMENT_NAME: ${{ steps.config.outputs.department_name }}
          VITE_COLOR_THEME: ${{ steps.config.outputs.color_theme }}
        run: pnpm run build:actions

      - name: Setup Pages
        uses: actions/configure-pages@v5

      - name: Upload Pages artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: dist

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
